{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/adult_train.csv')\n",
    "test = pd.read_csv('../data/adult_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.drop('target', axis=1)\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass_cat</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_cat</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status_cat</th>\n",
       "      <th>occupation_cat</th>\n",
       "      <th>relationship_cat</th>\n",
       "      <th>race_cat</th>\n",
       "      <th>sex_cat</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>77516</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>83311</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>215646</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>234721</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>338409</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass_cat  fnlwgt  education_cat  education-num  \\\n",
       "0   39              6   77516             11             13   \n",
       "1   50              5   83311             11             13   \n",
       "2   38              3  215646              8              9   \n",
       "3   53              3  234721              6              7   \n",
       "4   28              3  338409             11             13   \n",
       "\n",
       "   marital-status_cat  occupation_cat  relationship_cat  race_cat  sex_cat  \\\n",
       "0                   4               0                 1         4        1   \n",
       "1                   2               3                 0         4        1   \n",
       "2                   0               5                 1         4        1   \n",
       "3                   2               5                 0         2        1   \n",
       "4                   2               9                 5         2        0   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country_cat  \n",
       "0          2174             0              40                  38  \n",
       "1             0             0              13                  38  \n",
       "2             0             0              40                  38  \n",
       "3             0             0              40                  38  \n",
       "4             0             0              40                   4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanzhar/.virtualenvs/ml/lib/python3.6/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(18, input_dim=14, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Users/sanzhar/.virtualenvs/ml/lib/python3.6/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Users/sanzhar/.virtualenvs/ml/lib/python3.6/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(15, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Users/sanzhar/.virtualenvs/ml/lib/python3.6/site-packages/ipykernel/__main__.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Users/sanzhar/.virtualenvs/ml/lib/python3.6/site-packages/ipykernel/__main__.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(18, input_dim=X_train.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dense(12, init='uniform', activation='relu'))\n",
    "model.add(Dense(15, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.6898 - acc: 0.6772     \n",
      "Epoch 2/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.6583 - acc: 0.7659     \n",
      "Epoch 3/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5725 - acc: 0.7705     \n",
      "Epoch 4/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5596 - acc: 0.7798     \n",
      "Epoch 5/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5458 - acc: 0.7882     \n",
      "Epoch 6/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5361 - acc: 0.7927     \n",
      "Epoch 7/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5321 - acc: 0.7953     \n",
      "Epoch 8/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5275 - acc: 0.7933     \n",
      "Epoch 9/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5270 - acc: 0.7934     \n",
      "Epoch 10/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5268 - acc: 0.7935     \n",
      "Epoch 11/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5264 - acc: 0.7941     \n",
      "Epoch 12/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5252 - acc: 0.7931     \n",
      "Epoch 13/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5221 - acc: 0.7944     \n",
      "Epoch 14/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5214 - acc: 0.7951     \n",
      "Epoch 15/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5216 - acc: 0.7942     \n",
      "Epoch 16/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5186 - acc: 0.7942     \n",
      "Epoch 17/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5187 - acc: 0.7944     \n",
      "Epoch 18/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5202 - acc: 0.7963     \n",
      "Epoch 19/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5193 - acc: 0.7964     \n",
      "Epoch 20/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5183 - acc: 0.7952     \n",
      "Epoch 21/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5159 - acc: 0.7954     \n",
      "Epoch 22/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5150 - acc: 0.7961     \n",
      "Epoch 23/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5138 - acc: 0.7959     \n",
      "Epoch 24/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5138 - acc: 0.7967     \n",
      "Epoch 25/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5130 - acc: 0.7970     \n",
      "Epoch 26/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5147 - acc: 0.7974     \n",
      "Epoch 27/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5123 - acc: 0.7973     \n",
      "Epoch 28/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5119 - acc: 0.7973     \n",
      "Epoch 29/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5140 - acc: 0.7957     \n",
      "Epoch 30/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5105 - acc: 0.7977     \n",
      "Epoch 31/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5097 - acc: 0.7975     \n",
      "Epoch 32/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5088 - acc: 0.7981     \n",
      "Epoch 33/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5082 - acc: 0.7976     \n",
      "Epoch 34/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5092 - acc: 0.7977     \n",
      "Epoch 35/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5097 - acc: 0.7972     \n",
      "Epoch 36/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5078 - acc: 0.7989     \n",
      "Epoch 37/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5083 - acc: 0.7980     \n",
      "Epoch 38/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5072 - acc: 0.7977     \n",
      "Epoch 39/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5067 - acc: 0.7977     \n",
      "Epoch 40/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5089 - acc: 0.7970     \n",
      "Epoch 41/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5121 - acc: 0.7961     \n",
      "Epoch 42/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5079 - acc: 0.7987     \n",
      "Epoch 43/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5070 - acc: 0.7979     \n",
      "Epoch 44/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5059 - acc: 0.7973     \n",
      "Epoch 45/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5038 - acc: 0.7984     \n",
      "Epoch 46/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5039 - acc: 0.7989     \n",
      "Epoch 47/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5054 - acc: 0.7979     \n",
      "Epoch 48/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5061 - acc: 0.7988     \n",
      "Epoch 49/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5050 - acc: 0.7977     \n",
      "Epoch 50/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5032 - acc: 0.7991     \n",
      "Epoch 51/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5033 - acc: 0.7991     \n",
      "Epoch 52/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5016 - acc: 0.7997     \n",
      "Epoch 53/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5008 - acc: 0.7996     \n",
      "Epoch 54/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5046 - acc: 0.7977     \n",
      "Epoch 55/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5046 - acc: 0.7999     \n",
      "Epoch 56/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5000 - acc: 0.8006     \n",
      "Epoch 57/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4998 - acc: 0.7993     \n",
      "Epoch 58/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5002 - acc: 0.7999     \n",
      "Epoch 59/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5025 - acc: 0.7991     \n",
      "Epoch 60/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5021 - acc: 0.7991     \n",
      "Epoch 61/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4997 - acc: 0.8005     \n",
      "Epoch 62/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4997 - acc: 0.7996     \n",
      "Epoch 63/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4991 - acc: 0.7981     \n",
      "Epoch 64/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4974 - acc: 0.8006     \n",
      "Epoch 65/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4985 - acc: 0.7999     \n",
      "Epoch 66/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4983 - acc: 0.7999     \n",
      "Epoch 67/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4973 - acc: 0.8006     \n",
      "Epoch 68/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4962 - acc: 0.8013     \n",
      "Epoch 69/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4966 - acc: 0.8008     \n",
      "Epoch 70/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4978 - acc: 0.8008     \n",
      "Epoch 71/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5058 - acc: 0.7985     \n",
      "Epoch 72/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.5041 - acc: 0.7994     \n",
      "Epoch 73/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4994 - acc: 0.8009     \n",
      "Epoch 74/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4960 - acc: 0.8000     \n",
      "Epoch 75/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4964 - acc: 0.8002     \n",
      "Epoch 76/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4978 - acc: 0.7994     \n",
      "Epoch 77/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4943 - acc: 0.8013     \n",
      "Epoch 78/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4947 - acc: 0.8010     \n",
      "Epoch 79/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4965 - acc: 0.8006     \n",
      "Epoch 80/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4956 - acc: 0.8012     \n",
      "Epoch 81/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4953 - acc: 0.8017     \n",
      "Epoch 82/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4952 - acc: 0.8005     \n",
      "Epoch 83/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4945 - acc: 0.8011     \n",
      "Epoch 84/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4944 - acc: 0.8017     \n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21815/21815 [==============================] - 0s - loss: 0.4939 - acc: 0.8014     \n",
      "Epoch 86/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4945 - acc: 0.8009     \n",
      "Epoch 87/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4927 - acc: 0.8017     \n",
      "Epoch 88/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4920 - acc: 0.8023     \n",
      "Epoch 89/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4923 - acc: 0.8026     \n",
      "Epoch 90/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4916 - acc: 0.8027     \n",
      "Epoch 91/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4918 - acc: 0.8016     \n",
      "Epoch 92/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4916 - acc: 0.8026     \n",
      "Epoch 93/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4921 - acc: 0.8022     \n",
      "Epoch 94/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4912 - acc: 0.8014     \n",
      "Epoch 95/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4915 - acc: 0.8022     \n",
      "Epoch 96/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4929 - acc: 0.8016     \n",
      "Epoch 97/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4928 - acc: 0.8010     \n",
      "Epoch 98/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4936 - acc: 0.8013     \n",
      "Epoch 99/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4954 - acc: 0.7994     \n",
      "Epoch 100/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4934 - acc: 0.8009     \n",
      "Epoch 101/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4899 - acc: 0.8022     \n",
      "Epoch 102/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4900 - acc: 0.8027     \n",
      "Epoch 103/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4926 - acc: 0.8009     \n",
      "Epoch 104/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4903 - acc: 0.8041     \n",
      "Epoch 105/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4905 - acc: 0.8022     \n",
      "Epoch 106/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4947 - acc: 0.8004     \n",
      "Epoch 107/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4907 - acc: 0.8032     \n",
      "Epoch 108/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4931 - acc: 0.8023     \n",
      "Epoch 109/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4913 - acc: 0.8029     \n",
      "Epoch 110/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4929 - acc: 0.8015     \n",
      "Epoch 111/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4924 - acc: 0.8005     \n",
      "Epoch 112/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4901 - acc: 0.8022     \n",
      "Epoch 113/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4903 - acc: 0.8020     \n",
      "Epoch 114/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4900 - acc: 0.8026     \n",
      "Epoch 115/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4882 - acc: 0.8044     \n",
      "Epoch 116/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4912 - acc: 0.8024     \n",
      "Epoch 117/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4917 - acc: 0.8002     \n",
      "Epoch 118/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4926 - acc: 0.8023     \n",
      "Epoch 119/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4904 - acc: 0.8028     \n",
      "Epoch 120/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4895 - acc: 0.8023     \n",
      "Epoch 121/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4874 - acc: 0.8050     \n",
      "Epoch 122/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4885 - acc: 0.8027     \n",
      "Epoch 123/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4900 - acc: 0.8018     \n",
      "Epoch 124/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4872 - acc: 0.8047     \n",
      "Epoch 125/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4876 - acc: 0.8033     \n",
      "Epoch 126/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4873 - acc: 0.8048     \n",
      "Epoch 127/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4870 - acc: 0.8048     \n",
      "Epoch 128/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4881 - acc: 0.8034     \n",
      "Epoch 129/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4873 - acc: 0.8041     \n",
      "Epoch 130/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4900 - acc: 0.8021     \n",
      "Epoch 131/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4903 - acc: 0.8025     \n",
      "Epoch 132/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4884 - acc: 0.8032     \n",
      "Epoch 133/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4883 - acc: 0.8028     \n",
      "Epoch 134/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4869 - acc: 0.8046     \n",
      "Epoch 135/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4867 - acc: 0.8050     \n",
      "Epoch 136/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4876 - acc: 0.8045     \n",
      "Epoch 137/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4880 - acc: 0.8028     \n",
      "Epoch 138/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4879 - acc: 0.8037     \n",
      "Epoch 139/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4854 - acc: 0.8064     \n",
      "Epoch 140/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4861 - acc: 0.8052     \n",
      "Epoch 141/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4862 - acc: 0.8041     \n",
      "Epoch 142/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4856 - acc: 0.8053     \n",
      "Epoch 143/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4851 - acc: 0.8060     \n",
      "Epoch 144/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4873 - acc: 0.8043     \n",
      "Epoch 145/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4845 - acc: 0.8064     \n",
      "Epoch 146/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4844 - acc: 0.8058     \n",
      "Epoch 147/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4854 - acc: 0.8045     \n",
      "Epoch 148/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4846 - acc: 0.8055     \n",
      "Epoch 149/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4841 - acc: 0.8058     \n",
      "Epoch 150/150\n",
      "21815/21815 [==============================] - 0s - loss: 0.4914 - acc: 0.8018     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11bb57ba8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train.as_matrix(), y_train.as_matrix(), epochs=150, batch_size=2000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9312/10746 [========================>.....] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.98      0.89      8158\n",
      "          1       0.80      0.28      0.41      2588\n",
      "\n",
      "avg / total       0.81      0.81      0.77     10746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19328/21815 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80829704331881735"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model.predict_classes(X_train.as_matrix()), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14912/16281 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80793563048952766"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model.predict_classes(test.drop('target', axis=1).as_matrix()), test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
